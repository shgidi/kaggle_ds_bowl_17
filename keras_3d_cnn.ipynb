{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "/home/ubuntu/.local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/build/opencv-vU8_lj/opencv-2.4.9.1+dfsg/modules/imgproc/src/imgwarp.cpp:1834: error: (-215) ssize.area() > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a2d12a9b45d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/opencv-vU8_lj/opencv-2.4.9.1+dfsg/modules/imgproc/src/imgwarp.cpp:1834: error: (-215) ssize.area() > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "import theano\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# image specification\n",
    "img_rows,img_cols,img_depth=16,16,15\n",
    "\n",
    "\n",
    "# Training data\n",
    "\n",
    "X_tr=[]           # variable to store entire dataset\n",
    "\n",
    "#Reading boxing action class\n",
    "\n",
    "listing = os.listdir('/datadrive/keras_3d_sample/boxing')\n",
    "\n",
    "for vid in listing:\n",
    "    vid = '/datadrive/keras_3d_sample/'+vid\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "  \n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "#Reading hand clapping action class\n",
    "\n",
    "listing2 = os.listdir('/datadrive/keras_3d_sample/handclapping')\n",
    "\n",
    "for vid2 in listing2:\n",
    "    vid2 = '/datadrive/keras_3d_sample/handclapping/'+vid2\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid2)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "#Reading hand waving action class\n",
    "\n",
    "listing3 = os.listdir('/datadrive/keras_3d_sample/handwaving')\n",
    "\n",
    "for vid3 in listing3:\n",
    "    vid3 = '/datadrive/keras_3d_sample/handwaving/'+vid3\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid3)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "#Reading jogging action class\n",
    "\n",
    "listing4 = os.listdir('/datadtive/keras_3d_sample/jogging')\n",
    "\n",
    "for vid4 in listing4:\n",
    "    vid4 = '/datadtive/keras_3d_sample/jogging/'+vid4\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid4)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "#Reading running action class\n",
    "  \n",
    "listing5 = os.listdir('/datadrive/keras_3d_sample/running')\n",
    "\n",
    "for vid5 in listing5:\n",
    "    vid5 = '/datadrive/keras_3d_sample/running/'+vid5\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid5)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "  \n",
    "\n",
    "#Reading walking action class  \n",
    "\n",
    "listing6 = os.listdir('/datadrive/keras_3d_sample/walking')\n",
    "\n",
    "for vid6 in listing6:\n",
    "    vid6 = '/datadrive/keras_3d_sample/walking/'+vid6\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid6)\n",
    "    fps = cap.get(5)\n",
    "    print \"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps)\n",
    "\n",
    "    for k in xrange(15):\n",
    "        ret, frame = cap.read()\n",
    "        frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "\n",
    "        #plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "        #plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        #plt.show()\n",
    "        #cv2.imshow('frame',gray)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    input=np.array(frames)\n",
    "\n",
    "    print input.shape\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print ipt.shape\n",
    "\n",
    "    X_tr.append(ipt)\n",
    "\n",
    "\n",
    "\n",
    "X_tr_array = np.array(X_tr)   # convert the frames read into array\n",
    "\n",
    "num_samples = len(X_tr_array) \n",
    "print num_samples\n",
    "\n",
    "#Assign Label to each class\n",
    "\n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:100]= 0\n",
    "label[100:199] = 1\n",
    "label[199:299] = 2\n",
    "label[299:399] = 3\n",
    "label[399:499]= 4\n",
    "label[499:] = 5\n",
    "\n",
    "\n",
    "train_data = [X_tr_array,label]\n",
    "\n",
    "(X_train, y_train) = (train_data[0],train_data[1])\n",
    "print('X_Train shape:', X_train.shape)\n",
    "\n",
    "train_set = np.zeros((num_samples, 1, img_rows,img_cols,img_depth))\n",
    "\n",
    "for h in xrange(num_samples):\n",
    "    train_set[h][0][:][:][:]=X_train[h,:,:,:]\n",
    "  \n",
    "\n",
    "patch_size = 15    # img_depth or number of frames used for each video\n",
    "\n",
    "print(train_set.shape, 'train samples')\n",
    "\n",
    "# CNN Training parameters\n",
    "\n",
    "batch_size = 2\n",
    "nb_classes = 6\n",
    "nb_epoch =50\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "\n",
    "\n",
    "# number of convolutional filters to use at each layer\n",
    "nb_filters = [32, 32]\n",
    "\n",
    "# level of pooling to perform at each layer (POOL x POOL)\n",
    "nb_pool = [3, 3]\n",
    "\n",
    "# level of convolution to perform at each layer (CONV x CONV)\n",
    "nb_conv = [5,5]\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "\n",
    "train_set -= np.mean(train_set)\n",
    "\n",
    "train_set /=np.max(train_set)\n",
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution3D(nb_filters[0],nb_depth=nb_conv[0], nb_row=nb_conv[0], nb_col=nb_conv[0], input_shape=(1, img_rows, img_cols, patch_size), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, init='normal', activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes,init='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop')\n",
    "\n",
    "  \n",
    "# Split the data\n",
    "\n",
    "X_train_new, X_val_new, y_train_new,y_val_new =  train_test_split(train_set, Y_train, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "hist = model.fit(X_train_new, y_train_new, validation_data=(X_val_new,y_val_new),\n",
    "          batch_size=batch_size,nb_epoch = nb_epoch,show_accuracy=True,shuffle=True)\n",
    "\n",
    "\n",
    "#hist = model.fit(train_set, Y_train, batch_size=batch_size,\n",
    "#         nb_epoch=nb_epoch,validation_split=0.2, show_accuracy=True,\n",
    "#           shuffle=True)\n",
    "\n",
    "\n",
    " # Evaluate the model\n",
    "score = model.evaluate(X_val_new, y_val_new, batch_size=batch_size, show_accuracy=True)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1]) \n",
    "\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(100)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.open(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False None\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/build/opencv-vU8_lj/opencv-2.4.9.1+dfsg/modules/imgproc/src/color.cpp:3737: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fefc081d149e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Our operations on the frame come here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/opencv-vU8_lj/opencv-2.4.9.1+dfsg/modules/imgproc/src/color.cpp:3737: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(vid)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    print ret,frame\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
